```{r setup, include=FALSE, echo=FALSE}
require("knitr")
opts_knit$set(root.dir = "/home/samsl/Pseudotemporal-GRNs")
knitr::opts_chunk$set(echo = TRUE)
```

```{r "Load Libraries", warning=FALSE, include=TRUE, results='hide'}
require(bnlearn)
require(dplyr)
require(pscl)
require(Rgraphviz)
require(igraph)
require(circlize)
require(svglite)
require(ACTIONet)
require(SingleCellExperiment)
require(ComplexHeatmap)
require(splatter)
require(data.table)
```

```{r "Define functions"}
read.gmt <- function(file) {
  if (!grepl("\\.gmt$", file)[1]) {
    stop("Pathway information must be a .gmt file")
  }
  geneSetDB = readLines(file)
  geneSetDB = strsplit(geneSetDB, "\t")
  name = unlist(geneSetDB[1])
  desc = strsplit(geneSetDB[2][[1]],"> ")[[1]][2]
  geneSetDB = unlist(geneSetDB[-(1:2)])
  geneSetDB = list("name"=name,"description"=desc,"genes"=geneSetDB)
  return(geneSetDB)
}

# Rows = cells, Columns = genes
sim.df <- function(matrix,samplesize){
  rownames(matrix) <- c()
  rawdf <- as.data.frame(matrix)
  rawdf[] <- lapply(rawdf, factor)
  
  # network learning requires > 1 possible value for each var
  df <- select_if(rawdf,function(x) return(nlevels(x)>1))
  
  # learn from gene expression at each time step to generate data
  network <- hc(df)
  simdf <- rbn(network, data = df, samplesize)
  return(simdf)
}

sample.df <- function(matrix,samplesize){
  rownames(matrix) <- c()
  rawdf <- as.data.frame(matrix)
  rawdf[] <- lapply(rawdf, factor)
  
  # network learning requires > 1 possible value for each var
  sampled <- sample_n(rawdf,samplesize,replace = TRUE)
  sampled <- select_if(sampled,function(x) return(nlevels(x)>1))
  return(sampled)
}

sim.obs.from.distribution <- function (layers, N.SAMPLES, distribution="poisson") {
  simulated.df <- NULL
  
  if (!(distribution %in% c("poisson", "normal", "splatter"))) {
    stop("Invalid simulation distribution")
  }
  for (i in seq(K.clusters)) {
    if (distribution == "poisson") {
      means <- apply(layers[[i]],2,mean)
      layer.sims <- data.frame(lapply(data.frame(sapply(means, function(x){rpois(N.SAMPLES,x)})),as.numeric))
    }
    if (distribution == "normal") {
      means <- apply(layers[[i]],2,mean)
      std.devs <- apply(layers[[i]],2,sd)
      params <- data.frame(means,std.devs)
      layer.sims <- apply(params, 1, function(x){rnorm(N.SAMPLES, x[1], x[2])})
    }
    if (distribution == "splatter") {
      sim.layer <- layers[[i]][apply(layers[[i]],1,function(x){sum(x) > 0}),]
      dat.sce <- SingleCellExperiment(assays = list("counts"=t(sim.layer)))
      m1 <- splatEstimate(dat.sce)
      sim.sce <- splatSimulate(m1, batchCells=N.SAMPLES)
      rownames(sim.sce) <- colnames(sim.layer)
      layer.sims <- data.frame(lapply(data.frame(t(counts(sim.sce))), as.numeric))
    }
    
    colnames(layer.sims) <- colnames(layers[[i]])
    if (is.null(simulated.df)) {
      simulated.df <- layer.sims
    } else {
       simulated.df <- cbind(simulated.df, layer.sims) 
    }
  }
  return(data.frame(simulated.df))
}

create_df <- function(layers, sample.size, distribution="poisson"){
  bl <- data.frame()
  bndf <- NULL
  prevdf <- NULL
  prevcols <- c()
  
  bndf <- sim.obs.from.distribution(layers, sample.size, distribution = distribution)
  
  for (i in (1:K.clusters)){

    # only allow edges to future time points
    bl <- rbind(bl,
                expand.grid(colnames(layers[[i]]),prevcols),
                expand.grid(colnames(layers[[i]]),colnames(layers[[i]])))
  
    prevcols <- c(prevcols,colnames(layers[[i]]))
  }
  
  res <- list("df" = bndf, "bl" = bl)
  return(res)
}

write.sif <- function(file,network,df=NA) {
  if (!is.na(df)) {
    arcs = arc.strength(network, df)
    arcs$relation = rep.int("->",dim(arcs)[1])
    arcs$parentTime = apply(as.matrix(arcs$from), MARGIN=1, FUN=function (x) {as.numeric(strsplit(x,"_t")[[1]][2])})
    arcs = arcs[,c("from","relation","to","strength")]
    names(arcs) = c("Parent","-","Child","Weight")
  } else {
    arcs = network[["arcs"]]
    arcs = list("from"=arcs[,1],"to"=arcs[,2])
    arcs$relation = rep.int("->",length(arcs$from))
    arcs$parentTime = apply(as.matrix(arcs$from), MARGIN=1, FUN=function (x) {as.numeric(strsplit(x,"_t")[[1]][2])})
    arcs = data.frame(arcs)
    arcs = arcs[,c("from","relation","to")]
    names(arcs) = c("Parent","-","Child")
  }
  
  write.table(arcs,file=file, row.names = FALSE, quote = FALSE,sep=" ")
  nodeTimes = list("names"=names(network$nodes),"times"=apply(as.matrix(unlist(names(network$nodes))), MARGIN=1, FUN=function (x) {as.numeric(strsplit(x,"_t")[[1]][2])}))
  write.table(nodeTimes,paste0(file,".timetable"), row.names = FALSE, quote = FALSE, sep=" ")
}

plot.adjacency.matrix <- function(adjacency, path) {
  col_fun = colorRamp2(c(0, max(adjacency)), c("gray","red"))
  node.times.rows <- unlist(lapply(rownames(adjacency), function (x) {as.numeric(strsplit(x,"_t")[[1]][2])}))
  node.times.cols <- unlist(lapply(colnames(adjacency), function (x) {as.numeric(strsplit(x,"_t")[[1]][2])}))

  ht <- Heatmap(matrix(adjacency, dim(adjacency), dimnames = list(rownames(adjacency), colnames(adjacency))),
        name='Bootstrap Confidence', column_title="To", column_title_side="top", row_title="From", row_title_side="left",
        cluster_rows = FALSE, cluster_columns = FALSE, split = node.times.rows, column_split= node.times.cols,
        row_names_side = "left", column_names_side = "top",
        width = unit(30, "cm"), height = unit(30, "cm"), col=col_fun, border=TRUE, rect_gp = gpar(col = "white")) +
  rowAnnotation("Number of Children" = anno_barplot(apply(adjacency,1,function(x) {sum(x > 0)}), width = unit(4, "cm")))

  fig.size <- 1200
  if (endsWith(path, ".svg")) {
    svglite(path, width=fig.size, height=fig.size)
  } else {
    png(path, width=fig.size, height=fig.size)
  }
  HM <- draw(ht)
  dev.off()
}
```

```{r "Load and prepare data"}
# Select which data to load
cell.type = "Mic"
clusts <- readRDS(paste0("processed-data/",cell.type,"/clusters.rds"))
df <- as.data.frame(readRDS(paste0("processed-data/",cell.type,"/top_gene_counts.rds")))

# Load gene lists for network generation
marker.root <- "processed-data/markers/"
kegg <- read.gmt(paste0(marker.root,"KEGG_AD.gmt"))
adLib <- list("name"="library","description"="Library in AD SCE exeriment","genes"=colnames(df))
blalock_incpt_dn <- read.gmt(paste0(marker.root,"BLALOCK_INCPT_AD_DN.gmt"))
blalock_incpt_up <- read.gmt(paste0(marker.root,"BLALOCK_INCPT_AD_UP.gmt"))
blalock_dn <- read.gmt(paste0(marker.root,"BLALOCK_AD_DN.gmt"))
blalock_up <- read.gmt(paste0(marker.root,"BLALOCK_AD_UP.gmt"))
blalock <- list("name"="blalock","description"="All blalock","genes"=c(blalock_incpt_dn$genes, blalock_incpt_up$genes, blalock_dn$genes, blalock_up$genes))
gene.sets <- list("library"=adLib,"kegg"=kegg$genes,"incpt_dn"=blalock_incpt_dn$genes,"incpt_up"=blalock_incpt_up$genes,"dn"=blalock_dn$genes,"up"=blalock_up$genes,"blalock"=blalock)

# Select subset of genes
gene.df <- df[,intersect(adLib$genes,kegg$genes)]
```

```{r "Prepare layers"}
# Divide cells into layers based on clusters
clusts$ScoreClusts = as.numeric(clusts$DiseaseRange)
K.clusters = length(unique(clusts$ScoreClusts))

layers = list()
for (i in seq(K.clusters)) {
  layers[[i]] <- gene.df[clusts$ScoreClusts == i,]
  colnames(layers[[i]]) <- paste0(colnames(layers[[i]]),"_t",i)
}
gene.names <- unlist(list(cbind(unlist(lapply(layers,colnames)))))
```

```{r "Gene Expression Heatmap"}
mat <- NULL
for (i in seq(K.clusters)) {
  layer.mean <- apply(layers[[i]],2,mean)
  if (is.null(mat)) {
    mat <- data.table(layer.mean)
  } else {
    mat <- cbind(mat, data.table(layer.mean))
  }
}

# Find genes which cluster together with high change in expression across layers
avg.expression <- data.frame(mat)
rownames(avg.expression) <- names(gene.df)
colnames(avg.expression) <- c(1,2,3,4)
ht = Heatmap(avg.expression, cluster_columns = FALSE)
top.difeq.genes <- rownames(avg.expression)[row_order(ht)][1:30]
Heatmap(avg.expression[top.difeq.genes,], cluster_columns = FALSE)
```

```{r "Where do chosen genes rank among all genes?"}
chosen.genes <- top.difeq.genes
dbn.df <- gene.df[,chosen.genes]

# Recalculate layers with only chosen genes
reduced.layers = list()
for (i in seq(K.clusters)) {
  reduced.layers[[i]] <- dbn.df[clusts$ScoreClusts == i,]
  colnames(reduced.layers[[i]]) <- paste0(colnames(reduced.layers[[i]]),"_t",i)
}
gene.names <- unlist(list(cbind(unlist(lapply(reduced.layers,colnames)))))
```


```{r "Prepare data for GRNVBEM"}
# Write output for GRNVBEM
pseudotime.sorted <- t(dbn.df)[,order(clusts$DiseaseScore)]
write.csv(pseudotime.sorted, file=paste0("processed-data/",cell.type,"/GRNVBEM.csv"))
```

```{r, warning=FALSE}
# many different methods available for network learning
# network <- pc.stable(bndf,blacklist = bl)
# pc_network <- pc.stable(bndf, blacklist = bl, alpha = .05)[["arcs"]]
# gs_network <- gs(bndf, blacklist = bl, alpha = .05)[["arcs"]]

# --------MAIN LOOP----------- #
ITERS = 100
ALPHA = 0.05
interactions <- data.frame()

for (i in 1:ITERS){
  if (i %% 10 == 0) {print(i)}
  res <- create_df(reduced.layers, 5000, distribution = "poisson")
  bndf <- res$df
  bl <- res$bl
  fi_network <- fast.iamb(bndf, blacklist = bl, alpha = ALPHA)
  interactions <- rbind(interactions,fi_network[["arcs"]])
}
# -------------------------- #
```

```{r "Plot result network"}
BOOT.THRESH = 10
if (BOOT.THRESH >= ITERS) {
  warning("Removal threshold is greater than number of iterations")
}

if (ITERS > 1) {
  bootArcs <- interactions[duplicated(interactions),]
} else {
 bootArcs <- interactions 
}
bootArcs$from <- as.character(bootArcs$from)
bootArcs$to <- as.character(bootArcs$to)
adjacency <- table(bootArcs)
full.adjacency <- adjacency
print(table(full.adjacency))
adjacency[adjacency < BOOT.THRESH ] = 0L
saveRDS(interactions, paste0("processed-data/",cell.type,"/interactions.rds"))
saveRDS(adjacency, paste0("processed-data/",cell.type,"/bootAdjacency.rds"))
adjacency <- readRDS(paste0("processed-data/",cell.type,"/bootAdjacency.rds"))
print(table(adjacency))

network <- empty.graph(gene.names)
adj <- melt.data.table(data.table(adjacency), id.vars = c('from','to'))
adj <- adj[adj$value > 0]
arcs(network) <- cbind(adj$from, adj$to)

# output edges of graph
groups <- list()
for (i in seq(K.clusters)) {
  groups[[i]] <- names(network$nodes)[grep(paste0(".*_t",i),names(network$nodes))]
}
graphviz.plot(network,groups=groups)
```

```{r "Explore result network"}
# Numbers of parents & children
n.parents = unlist(lapply(network$nodes, function (x) {length(x$parents)}))
n.children = unlist(lapply(network$nodes, function (x) {length(x$children)}))
# Node degrees
n.degree = unlist(lapply(c(n.parents,n.children), sum))
plot(density(n.children))
```

```{r "Visualize network"}
plot.adjacency.matrix(adjacency, "test.png")
#plot.adjacency.matrix(adjacency, paste0("img/",cell.type,".adjacency3.png"))
```

```{r "Verify simulated data"}
simulated.dat <- bndf
sim.mat <- NULL
for (i in seq(K.clusters)) {
  sim.layer <- simulated.dat[,((i-1)*length(chosen.genes)+1):(i * length(chosen.genes))]
  sim.layer.mean <- apply(data.frame(sim.layer),2,mean)
  if (is.null(mat)) {
    sim.mat <- data.table(sim.layer.mean)
  } else {
    sim.mat <- cbind(sim.mat, data.table(sim.layer.mean))
  }
}

# Find genes which cluster together with high change in expression across layers
sim.avg.expression <- data.frame(sim.mat)
rownames(sim.avg.expression) <- chosen.genes
colnames(sim.avg.expression) <- c(1,2,3,4)
Heatmap(sim.avg.expression, cluster_columns = FALSE)


sim.avg.expr <- apply(simulated.dat, 1, mean)
names(simulated.dat) <- rep(names(chosen.genes), 4)
```

```{r}
stacked.dat <- NULL
for (i in seq(K.clusters)) {
  sim.layer <- simulated.dat[,((i-1)*length(chosen.genes)+1):(i * length(chosen.genes))]
  colnames(sim.layer) <- chosen.genes
  if (is.null(stacked.dat)) {
    stacked.dat <- data.table(sim.layer)
  } else {
    stacked.dat <- rbind(stacked.dat, data.table(sim.layer))
  }
}

sim.dat.layer=c(rep(1,10000), rep(2,10000), rep(3,10000), rep(4,10000))
sim.sce <- SingleCellExperiment(assays = list(logcounts = t(stacked.dat)))
colData(sim.sce)$layer <- sim.dat.layer
reduced.sim.sce <- ACTIONet::reduce.sce(sim.sce)
verif.ACTIONet <- run.ACTIONet(reduced.sim.sce, k_max = 20, thread_no = 12)
```

```{r "Export network"}
# SIF
write.sif(paste0("processed-data/",cell.type,"/DBN.sif"), network)
```
